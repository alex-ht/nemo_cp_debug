examples/nlp/gpt/train_gpt_sft.py trainer.precision=16-mixed trainer.num_nodes=16 trainer.devices=-1 trainer.sft.limit_val_batches=1 trainer.sft.val_check_interval=12 trainer.sft.save_interval=12 model.megatron_amp_O2=True model.restore_from_path=/home/u9824269/LLM/llama3/train/llama3-70b-chat-16-mixed.nemo model.optim.lr=5e-6 model.optim.name=distributed_fused_adam model.answer_only_loss=True model.data.num_workers=0 model.data.train_ds.micro_batch_size=1 model.data.train_ds.global_batch_size=8 model.data.train_ds.file_path=/home/u9824269/LLM/nemo/databricks-dolly-15k-output.jsonl model.data.train_ds.max_seq_length=8192 model.data.train_ds.add_eos=True model.data.train_ds.add_bos=True +model.data.train_ds.packed_sequence=True model.data.validation_ds.max_seq_length=8192 model.data.validation_ds.micro_batch_size=1 model.data.validation_ds.global_batch_size=128 model.data.validation_ds.file_path=/home/u9824269/LLM/nemo/databricks-dolly-15k-output.jsonl model.data.validation_ds.add_bos=True model.data.validation_ds.add_eos=True +model.data.validation_ds.packed_sequence=True model.tensor_model_parallel_size=8 model.pipeline_model_parallel_size=4 model.sequence_parallel=False model.activations_checkpoint_granularity=selective model.activations_checkpoint_method=uniform +model.context_parallel_size=2 exp_manager.create_wandb_logger=True exp_manager.explicit_log_dir=/home/u9824269/LLM/llama3/train/result_dir exp_manager.wandb_logger_kwargs.project=llama3-test exp_manager.wandb_logger_kwargs.name=dolly_sft_run_tp8 exp_manager.resume_if_exists=True exp_manager.resume_ignore_no_checkpoint=True exp_manager.create_checkpoint_callback=True exp_manager.checkpoint_callback_params.save_nemo_on_train_end=True exp_manager.checkpoint_callback_params.monitor=validation_loss