
=============
== PyTorch ==
=============

NVIDIA Release 24.02 (build 82611821)
PyTorch Version 2.3.0a0+ebedce2
Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

ERROR: This container was built for NVIDIA Driver Release 545.23 or later, but
       version 470.161.03 was detected and compatibility mode is UNAVAILABLE.

       [[]]

gn1124:32228:32228 [7] NCCL INFO cudaDriverVersion 12030
gn1124:32228:32228 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
gn1124:32228:32228 [7] NCCL INFO Bootstrap : Using ib0:10.100.11.24<0>
gn1124:32228:32228 [7] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
gn1124:32228:32228 [7] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
gn1124:32228:32228 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
gn1124:32228:32228 [7] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
gn1124:32228:13356 [7] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
gn1124:32228:13356 [7] NCCL INFO P2P plugin IBext
gn1124:32228:13356 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ib0
gn1124:32228:13356 [7] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [RO]; OOB ib0:10.100.11.24<0>
gn1124:32228:13356 [7] NCCL INFO Using non-device net plugin version 0
gn1124:32228:13356 [7] NCCL INFO Using network IBext
gn1124:32228:13356 [7] NCCL INFO comm 0x5574aa5f08f0 rank 31 nranks 128 cudaDev 7 nvmlDev 7 busId dc000 commId 0xc30115f52475687c - Init START
gn1124:32228:13356 [7] NCCL INFO Setting affinity for GPU 7 to 3c0000
gn1124:32228:13356 [7] NCCL INFO NVLS multicast support is not available on dev 7
gn1124:32228:13356 [7] NCCL INFO Trees [0] 28/-1/-1->31->30 [1] 28/-1/-1->31->30
gn1124:32228:13356 [7] NCCL INFO P2P Chunksize set to 131072
gn1124:32228:13356 [7] NCCL INFO Channel 00/0 : 31[7] -> 25[1] via P2P/CUMEM
gn1124:32228:13356 [7] NCCL INFO Channel 01/0 : 31[7] -> 25[1] via P2P/CUMEM
gn1124:32228:13356 [7] NCCL INFO Connected all rings
gn1124:32228:13356 [7] NCCL INFO Channel 00/0 : 31[7] -> 28[4] via P2P/CUMEM
gn1124:32228:13356 [7] NCCL INFO Channel 01/0 : 31[7] -> 28[4] via P2P/CUMEM
gn1124:32228:13356 [7] NCCL INFO Channel 00/0 : 31[7] -> 30[6] via P2P/CUMEM
gn1124:32228:13356 [7] NCCL INFO Channel 01/0 : 31[7] -> 30[6] via P2P/CUMEM
gn1124:32228:13356 [7] NCCL INFO Connected all trees
gn1124:32228:13356 [7] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
gn1124:32228:13356 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
gn1124:32228:13356 [7] NCCL INFO Channel 00/1 : 31[7] -> 24[0] via P2P/indirect/30[6]
gn1124:32228:13356 [7] NCCL INFO Channel 01/1 : 31[7] -> 24[0] via P2P/indirect/30[6]
gn1124:32228:13356 [7] NCCL INFO Channel 00/1 : 31[7] -> 26[2] via P2P/indirect/25[1]
gn1124:32228:13356 [7] NCCL INFO Channel 01/1 : 31[7] -> 26[2] via P2P/indirect/25[1]
gn1124:32228:13356 [7] NCCL INFO Channel 00/1 : 31[7] -> 27[3] via P2P/indirect/25[1]
gn1124:32228:13356 [7] NCCL INFO Channel 01/1 : 31[7] -> 27[3] via P2P/indirect/25[1]
gn1124:32228:13356 [7] NCCL INFO comm 0x5574aa5f08f0 rank 31 nranks 128 cudaDev 7 nvmlDev 7 busId dc000 commId 0xc30115f52475687c - Init COMPLETE
gn1124:32228:19217 [7] NCCL INFO Using non-device net plugin version 0
gn1124:32228:19217 [7] NCCL INFO Using network IBext
gn1124:32228:19217 [7] NCCL INFO comm 0x5574ad122490 rank 7 nranks 32 cudaDev 7 nvmlDev 7 busId dc000 commId 0x39bb5eaddc5bac6e - Init START
gn1124:32228:19217 [7] NCCL INFO Setting affinity for GPU 7 to 3c0000
gn1124:32228:19217 [7] NCCL INFO NVLS multicast support is not available on dev 7
gn1124:32228:19217 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6
gn1124:32228:19217 [7] NCCL INFO P2P Chunksize set to 131072
gn1124:32228:19217 [7] NCCL INFO Channel 00/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19217 [7] NCCL INFO Channel 01/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19217 [7] NCCL INFO Connected all rings
gn1124:32228:19217 [7] NCCL INFO Channel 00/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19217 [7] NCCL INFO Channel 01/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19217 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/CUMEM
gn1124:32228:19217 [7] NCCL INFO Channel 01/0 : 7[7] -> 6[6] via P2P/CUMEM
gn1124:32228:19217 [7] NCCL INFO Connected all trees
gn1124:32228:19217 [7] NCCL INFO threadThresholds 8/8/64 | 256/8/64 | 512 | 512
gn1124:32228:19217 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
gn1124:32228:19217 [7] NCCL INFO Channel 00/1 : 7[7] -> 0[0] via P2P/indirect/6[6]
gn1124:32228:19217 [7] NCCL INFO Channel 01/1 : 7[7] -> 0[0] via P2P/indirect/6[6]
gn1124:32228:19217 [7] NCCL INFO Channel 00/1 : 7[7] -> 2[2] via P2P/indirect/1[1]
gn1124:32228:19217 [7] NCCL INFO Channel 01/1 : 7[7] -> 2[2] via P2P/indirect/1[1]
gn1124:32228:19217 [7] NCCL INFO Channel 00/1 : 7[7] -> 3[3] via P2P/indirect/1[1]
gn1124:32228:19217 [7] NCCL INFO Channel 01/1 : 7[7] -> 3[3] via P2P/indirect/1[1]
gn1124:32228:19217 [7] NCCL INFO comm 0x5574ad122490 rank 7 nranks 32 cudaDev 7 nvmlDev 7 busId dc000 commId 0x39bb5eaddc5bac6e - Init COMPLETE
gn1124:32228:19650 [7] NCCL INFO Using non-device net plugin version 0
gn1124:32228:19650 [7] NCCL INFO Using network IBext
gn1124:32228:19650 [7] NCCL INFO comm 0x5574b772e6e0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId dc000 commId 0x606a6bf689b8b2c7 - Init START
gn1124:32228:19650 [7] NCCL INFO Setting affinity for GPU 7 to 3c0000
gn1124:32228:19650 [7] NCCL INFO NVLS multicast support is not available on dev 7
gn1124:32228:19650 [7] NCCL INFO Trees [0] 4/-1/-1->7->1 [1] 4/-1/-1->7->1 [2] 1/-1/-1->7->4 [3] 1/-1/-1->7->4 [4] 6/-1/-1->7->5 [5] 5/-1/-1->7->6 [6] 4/-1/-1->7->1 [7] 4/-1/-1->7->1 [8] 1/-1/-1->7->4 [9] 1/-1/-1->7->4 [10] 6/-1/-1->7->5 [11] 5/-1/-1->7->6
gn1124:32228:19650 [7] NCCL INFO P2P Chunksize set to 524288
gn1124:32228:19650 [7] NCCL INFO Channel 02/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 03/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 08/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 09/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 00/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 01/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 06/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 07/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 05/0 : 7[7] -> 5[5] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 11/0 : 7[7] -> 5[5] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 04/0 : 7[7] -> 6[6] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 10/0 : 7[7] -> 6[6] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Connected all rings
gn1124:32228:19650 [7] NCCL INFO Channel 00/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 01/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 06/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 07/0 : 7[7] -> 1[1] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 02/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 03/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 08/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 09/0 : 7[7] -> 4[4] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 04/0 : 7[7] -> 5[5] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 10/0 : 7[7] -> 5[5] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 05/0 : 7[7] -> 6[6] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Channel 11/0 : 7[7] -> 6[6] via P2P/CUMEM
gn1124:32228:19650 [7] NCCL INFO Connected all trees
gn1124:32228:19650 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn1124:32228:19650 [7] NCCL INFO 12 coll channels, 0 nvls channels, 16 p2p channels, 2 p2p channels per peer
gn1124:32228:19650 [7] NCCL INFO Channel 08/1 : 7[7] -> 0[0] via P2P/indirect/6[6]
gn1124:32228:19650 [7] NCCL INFO Channel 09/1 : 7[7] -> 0[0] via P2P/indirect/6[6]
gn1124:32228:19650 [7] NCCL INFO Channel 12/1 : 7[7] -> 2[2] via P2P/indirect/1[1]
gn1124:32228:19650 [7] NCCL INFO Channel 13/1 : 7[7] -> 2[2] via P2P/indirect/1[1]
gn1124:32228:19650 [7] NCCL INFO Channel 02/1 : 7[7] -> 3[3] via P2P/indirect/1[1]
gn1124:32228:19650 [7] NCCL INFO Channel 03/1 : 7[7] -> 3[3] via P2P/indirect/1[1]
gn1124:32228:19650 [7] NCCL INFO comm 0x5574b772e6e0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId dc000 commId 0x606a6bf689b8b2c7 - Init COMPLETE
NCCL version 2.19.4+cuda12.3
gn1124:32228:20753 [7] NCCL INFO Using non-device net plugin version 0
gn1124:32228:20753 [7] NCCL INFO Using network IBext
gn1124:32228:20753 [7] NCCL INFO comm 0x5574bd4b7d10 rank 0 nranks 4 cudaDev 7 nvmlDev 7 busId dc000 commId 0x2adc344e84bafae3 - Init START
gn1124:32228:20753 [7] NCCL INFO Setting affinity for GPU 7 to 3c0000
gn1124:32228:20753 [7] NCCL INFO Channel 00/02 :    0   1   2   3
gn1124:32228:20753 [7] NCCL INFO Channel 01/02 :    0   1   2   3
gn1124:32228:20753 [7] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] -1/-1/-1->0->1
gn1124:32228:20753 [7] NCCL INFO P2P Chunksize set to 131072
gn1124:32228:20753 [7] NCCL INFO Channel 00/0 : 3[7] -> 0[7] [receive] via NET/IBext/0
gn1124:32228:20753 [7] NCCL INFO Channel 01/0 : 3[7] -> 0[7] [receive] via NET/IBext/0
gn1124:32228:20753 [7] NCCL INFO Channel 00/0 : 0[7] -> 1[7] [send] via NET/IBext/0
gn1124:32228:20753 [7] NCCL INFO Channel 01/0 : 0[7] -> 1[7] [send] via NET/IBext/0
gn1124:32228:20753 [7] NCCL INFO Connected all rings
gn1124:32228:20753 [7] NCCL INFO Channel 00/0 : 2[7] -> 0[7] [receive] via NET/IBext/0
gn1124:32228:20753 [7] NCCL INFO Channel 00/0 : 0[7] -> 2[7] [send] via NET/IBext/0
gn1124:32228:20753 [7] NCCL INFO Channel 01/0 : 1[7] -> 0[7] [receive] via NET/IBext/0
gn1124:32228:20753 [7] NCCL INFO Connected all trees
gn1124:32228:20753 [7] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn1124:32228:20753 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
gn1124:32228:20753 [7] NCCL INFO comm 0x5574bd4b7d10 rank 0 nranks 4 cudaDev 7 nvmlDev 7 busId dc000 commId 0x2adc344e84bafae3 - Init COMPLETE
gn1124:32228:20772 [7] NCCL INFO Channel 00/1 : 0[7] -> 1[7] [send] via NET/IBext/0/Shared
gn1124:32228:20772 [7] NCCL INFO Channel 01/1 : 0[7] -> 1[7] [send] via NET/IBext/0/Shared
gn1124:32228:21018 [7] NCCL INFO Channel 00/1 : 1[7] -> 0[7] [receive] via NET/IBext/0/Shared
gn1124:32228:21018 [7] NCCL INFO Channel 01/1 : 1[7] -> 0[7] [receive] via NET/IBext/0/Shared
gn1124:32228:24211 [7] NCCL INFO Using non-device net plugin version 0
gn1124:32228:24211 [7] NCCL INFO Using network IBext
gn1124:32228:24211 [7] NCCL INFO comm 0x2b1ab6f0eb00 rank 3 nranks 4 cudaDev 7 nvmlDev 7 busId dc000 commId 0x5aa8c572bc6d40ba - Init START
gn1124:32228:24211 [7] NCCL INFO Setting affinity for GPU 7 to 3c0000
gn1124:32228:24211 [7] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 1/-1/-1->3->-1
gn1124:32228:24211 [7] NCCL INFO P2P Chunksize set to 131072
gn1124:32228:24211 [7] NCCL INFO Channel 00/0 : 2[7] -> 3[7] [receive] via NET/IBext/0
gn1124:32228:24211 [7] NCCL INFO Channel 01/0 : 2[7] -> 3[7] [receive] via NET/IBext/0
gn1124:32228:24211 [7] NCCL INFO Channel 00/0 : 3[7] -> 0[7] [send] via NET/IBext/0
gn1124:32228:24211 [7] NCCL INFO Channel 01/0 : 3[7] -> 0[7] [send] via NET/IBext/0
gn1124:32228:24211 [7] NCCL INFO Connected all rings
gn1124:32228:24211 [7] NCCL INFO Channel 01/0 : 1[7] -> 3[7] [receive] via NET/IBext/0
gn1124:32228:24211 [7] NCCL INFO Channel 01/0 : 3[7] -> 1[7] [send] via NET/IBext/0
gn1124:32228:24211 [7] NCCL INFO Channel 00/0 : 3[7] -> 2[7] [send] via NET/IBext/0
gn1124:32228:24211 [7] NCCL INFO Connected all trees
gn1124:32228:24211 [7] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn1124:32228:24211 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
gn1124:32228:24211 [7] NCCL INFO comm 0x2b1ab6f0eb00 rank 3 nranks 4 cudaDev 7 nvmlDev 7 busId dc000 commId 0x5aa8c572bc6d40ba - Init COMPLETE
gn1124:32228:24264 [7] NCCL INFO [Service thread] Connection closed by localRank 0
gn1124:32228:32228 [7] NCCL INFO comm 0x2b1ab6f0eb00 rank 3 nranks 4 cudaDev 7 busId dc000 - Abort COMPLETE
gn1124:32228:19221 [7] NCCL INFO [Service thread] Connection closed by localRank 7
gn1124:32228:19221 [7] NCCL INFO [Service thread] Connection closed by localRank 6
gn1124:32228:19221 [7] NCCL INFO [Service thread] Connection closed by localRank 1
