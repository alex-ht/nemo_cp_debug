13:4: not a valid test operator: (
13:4: not a valid test operator: 470.161.03
[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Initializing distributed: GLOBAL_RANK: 104, MEMBER: 105/128
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
Training steps:   0%|          | 0/1876 [00:00<?, ?it/s]Training steps:   0%|          | 0/1876 [01:59<?, ?it/s, train_grad_norm=nan, train_lr=0, train_loss=1.57, train_consumed_samples=8, train_step_time=116, train_epoch=1]Training steps:   0%|          | 1/1876 [01:59<62:14:15, 119.50s/it, train_grad_norm=nan, train_lr=0, train_loss=1.57, train_consumed_samples=8, train_step_time=116, train_epoch=1]Training steps:   0%|          | 1/1876 [02:40<62:14:15, 119.50s/it, train_grad_norm=nan, train_lr=5e-7, train_loss=1.44, train_consumed_samples=16, train_step_time=38.3, train_epoch=1]Training steps:   0%|          | 2/1876 [02:40<38:09:21, 73.30s/it, train_grad_norm=nan, train_lr=5e-7, train_loss=1.44, train_consumed_samples=16, train_step_time=38.3, train_epoch=1] Training steps:   0%|          | 2/1876 [03:21<38:09:21, 73.30s/it, train_grad_norm=nan, train_lr=1e-6, train_loss=1.3, train_consumed_samples=24, train_step_time=37.2, train_epoch=1] Training steps:   0%|          | 3/1876 [03:21<30:29:46, 58.62s/it, train_grad_norm=nan, train_lr=1e-6, train_loss=1.3, train_consumed_samples=24, train_step_time=37.2, train_epoch=1]Training steps:   0%|          | 3/1876 [04:03<30:29:46, 58.62s/it, train_grad_norm=nan, train_lr=1.5e-6, train_loss=2.57, train_consumed_samples=32, train_step_time=38.3, train_epoch=1]Training steps:   0%|          | 4/1876 [04:03<27:06:18, 52.13s/it, train_grad_norm=nan, train_lr=1.5e-6, train_loss=2.57, train_consumed_samples=32, train_step_time=38.3, train_epoch=1]Training steps:   0%|          | 4/1876 [04:44<27:06:18, 52.13s/it, train_grad_norm=nan, train_lr=2e-6, train_loss=1.76, train_consumed_samples=40, train_step_time=38.6, train_epoch=1]  Training steps:   0%|          | 5/1876 [04:44<25:02:42, 48.19s/it, train_grad_norm=nan, train_lr=2e-6, train_loss=1.76, train_consumed_samples=40, train_step_time=38.6, train_epoch=1]Training steps:   0%|          | 5/1876 [05:26<25:02:42, 48.19s/it, train_grad_norm=nan, train_lr=2.5e-6, train_loss=1.84, train_consumed_samples=48, train_step_time=38.4, train_epoch=1]Training steps:   0%|          | 6/1876 [05:26<23:52:34, 45.96s/it, train_grad_norm=nan, train_lr=2.5e-6, train_loss=1.84, train_consumed_samples=48, train_step_time=38.4, train_epoch=1]Training steps:   0%|          | 6/1876 [06:08<23:52:34, 45.96s/it, train_grad_norm=nan, train_lr=3e-6, train_loss=1.87, train_consumed_samples=56, train_step_time=38, train_epoch=1]    Training steps:   0%|          | 7/1876 [06:08<23:06:51, 44.52s/it, train_grad_norm=nan, train_lr=3e-6, train_loss=1.87, train_consumed_samples=56, train_step_time=38, train_epoch=1]Training steps:   0%|          | 7/1876 [06:49<23:06:51, 44.52s/it, train_grad_norm=nan, train_lr=3.5e-6, train_loss=1.22, train_consumed_samples=64, train_step_time=38.7, train_epoch=1]Training steps:   0%|          | 8/1876 [06:49<22:32:22, 43.44s/it, train_grad_norm=nan, train_lr=3.5e-6, train_loss=1.22, train_consumed_samples=64, train_step_time=38.7, train_epoch=1]Training steps:   0%|          | 8/1876 [07:30<22:32:22, 43.44s/it, train_grad_norm=nan, train_lr=4e-6, train_loss=1.46, train_consumed_samples=72, train_step_time=38.1, train_epoch=1]  Training steps:   0%|          | 9/1876 [07:30<22:10:27, 42.76s/it, train_grad_norm=nan, train_lr=4e-6, train_loss=1.46, train_consumed_samples=72, train_step_time=38.1, train_epoch=1]Training steps:   0%|          | 9/1876 [08:11<22:10:27, 42.76s/it, train_grad_norm=nan, train_lr=4.5e-6, train_loss=1.37, train_consumed_samples=80, train_step_time=38.7, train_epoch=1]Training steps:   1%|          | 10/1876 [08:11<21:56:16, 42.32s/it, train_grad_norm=nan, train_lr=4.5e-6, train_loss=1.37, train_consumed_samples=80, train_step_time=38.7, train_epoch=1]Training steps:   1%|          | 10/1876 [08:52<21:56:16, 42.32s/it, train_grad_norm=nan, train_lr=5e-6, train_loss=1.75, train_consumed_samples=88, train_step_time=38.3, train_epoch=1]  Training steps:   1%|          | 11/1876 [08:52<21:34:45, 41.65s/it, train_grad_norm=nan, train_lr=5e-6, train_loss=1.75, train_consumed_samples=88, train_step_time=38.3, train_epoch=1]
Validation steps:   0%|          | 0/1 [00:00<?, ?it/s][A
Validation steps:   0%|          | 0/1 [01:20<?, ?it/s, val_loss=1.64, val_validation_step_time=63.8][A
Validation steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:20<00:00, 80.05s/it, val_loss=1.64, val_validation_step_time=63.8][AValidation steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:20<00:00, 80.05s/it, val_loss=1.64, val_validation_step_time=63.8]
Training steps:   1%|          | 11/1876 [10:52<21:34:45, 41.65s/it, train_grad_norm=nan, train_lr=5e-6, train_loss=1.92, train_consumed_samples=96, train_step_time=37.9, train_epoch=1, val_loss=1.64, val_validation_step_time=63.8]/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
